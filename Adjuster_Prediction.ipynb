{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "current_dir = os.getcwd();\n",
    "vocab_size=10000\n",
    "max_len=200\n",
    "max_words=10000\n",
    "sample_size=500 #sample reocrds\n",
    "train_size= 6000 # number of samples to use to train model\n",
    "dropout_rate=0.2\n",
    "size_embedding=10000\n",
    "batch_size=128\n",
    "epochs=30\n",
    "num_gpu=2\n",
    "lbl = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model directory if not present\n",
    "%mkdir model#model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_dir = current_dir + '/model/grp_type_bst_model.hdf5' # save best models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tensorboard directory if not present\n",
    "%mkdir tensorB #tensorboard directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_dir=\"./group_type\" #tensor board sub directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check available devices , how many GPU & CPU\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Memory Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_mem():\n",
    "    K.get_session().close()\n",
    "    cfg = K.tf.ConfigProto(allow_soft_placement=True,log_device_placement=True)\n",
    "    cfg.gpu_options.allow_growth = True\n",
    "    K.set_session(K.tf.Session(config=cfg))\n",
    "limit_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=os.getcwd()\n",
    "df = pd.read_csv('group_type_data_2017_10_types.csv',low_memory =False)\n",
    "print(\"Shape of dataset {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove unamed columns if present\n",
    "df =  df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No Sampling for now\n",
    "#blank group types into uncategorised\n",
    "#df.group_type.fillna(\"Uncategorised\", inplace=True)\n",
    "#sampling equal records from each class for sample dataset\n",
    "#df=df.groupby('group_type').apply(lambda x: x.sample(sample_size)).reset_index(drop=True) # to create sample of equal class size\n",
    "#print(\"Shape of sample data {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of the dataframe\n",
    "size=len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ID column combination of other column\n",
    "ID = df['claim_claimnumber'].astype(str)+ ',' + df['exp_claimorder'].astype(str) \n",
    "# replacing blanks with 0 in target variable\n",
    "df.group_type.fillna(\"Uncategorised\",inplace=True) \n",
    "#dropping columns which has more than 20% blanks\n",
    "df=df.dropna(thresh=0.8*len(df),axis=1)\n",
    "#more columns to drop \n",
    "cols_to_drop=['claim_claimnumber','exp_claimorder','inc_veh_model','inc_veh_vin','claimant_addr_postalcodedenorm','claimant_cont_licensenumber']\n",
    "#drop above columns\n",
    "df.drop(cols_to_drop,axis=1,inplace=True)\n",
    "print('shape of dataframe {}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine unique values in each column\n",
    "for col in df.columns:\n",
    "    print(\"{} has {} unique values\".format(col,len(df[col].value_counts())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = df.group_type\n",
    "df.drop(['group_type'],axis=1,inplace=True)\n",
    "print(\"target variable drop from training data, shape of training data {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify text & categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = 'claim_description'\n",
    "cat_features = [col for col in df.columns if col not in text_features]\n",
    "#cat_features_hash = [col+\"_hash\" for col in cat_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Categroical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean categorical data\n",
    "for col in cat_features:\n",
    "    if df[col].dtypes=='O':\n",
    "        df[col].fillna(\"unk\",inplace=True)  #replace blank categories as unknown\n",
    "        df[col]=df[col].apply(lambda x : clean_categorical_data(x))\n",
    "print(\"Categorical columns cleaning done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_features:    \n",
    "    df[col] = pd.factorize(df[col])[0]\n",
    "print(\"Categroical features are encoded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Claim Description clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "df['claim_description'] =df.claim_description.apply(lambda x : clean(x))\n",
    "print(\"Time taken to clean {} mins\".format((time.time()-start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_cat = df[cat_features].values #categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):    \n",
    "    tokenizer = Tokenizer(num_words=max_words)\n",
    "    tokenizer.fit_on_texts(text) \n",
    "    trn_text = tokenizer.texts_to_sequences(text)\n",
    "    train_text = pad_sequences(trn_text,maxlen=max_len)\n",
    "    return train_text\n",
    "trn_text = tokenize(df['claim_description']) #text feature\n",
    "print(\"Text data shape {}\".format(trn_text.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target variable label encoding and one hot encode\n",
    "lbl.fit(target)\n",
    "encoded_target = lbl.transform(target)\n",
    "encoded_target= tf.keras.utils.to_categorical(encoded_target,num_classes=None)\n",
    "print(\"Output shape {}\".format(encoded_target.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():    \n",
    "        # categorical channel\n",
    "        with tf.name_scope(\"Input_Category\"):\n",
    "            inputs1 = Input(shape=(trn_cat.shape[1],))\n",
    "        with tf.name_scope('Dense_cat'):\n",
    "            dense_cat_1 = Dense(256, activation='relu')(inputs1)\n",
    "            dense_cat_2 = Dense(32, activation='relu')(dense_cat_1)\n",
    "        with tf.name_scope('Flat_1'):\n",
    "            flat1 = Dense(32, activation='relu')(dense_cat_2)\n",
    "\n",
    "\n",
    "        # text channel\n",
    "        with tf.name_scope('Input_Text'):\n",
    "            inputs2 = Input(shape=(trn_text.shape[1],))\n",
    "            embedding2 = Embedding(size_embedding, 50,)(inputs2)\n",
    "        with tf.name_scope('GRU'):\n",
    "            gru = Bidirectional(GRU(256,return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(embedding2)\n",
    "        with tf.name_scope('Convolution'):    \n",
    "            conv1 = Conv1D(filters=32, kernel_size=8, activation='relu')(gru)\n",
    "        with tf.name_scope('Dropout'):\n",
    "            drop1 = Dropout(dropout_rate)(conv1)\n",
    "        with tf.name_scope('MaxPool'):\n",
    "            pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "        with tf.name_scope('Flat_2'):\n",
    "            flat2 = Flatten()(pool1)\n",
    "\n",
    "        # merge\n",
    "        with tf.name_scope('Merge'):\n",
    "            merged = concatenate([flat1,flat2])\n",
    "        with tf.name_scope('Dense'):\n",
    "            dense1 = Dense(200, activation='relu')(merged)\n",
    "            dense2 = Dense(20, activation='relu')(dense1)\n",
    "        with tf.name_scope('Output'):\n",
    "            outputs = Dense(12, activation='softmax')(dense2)\n",
    "        model = Model(inputs=[inputs1,inputs2], outputs=outputs)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD,Adamax,Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=1e-5),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### For multi gpus \n",
    "#first run model on single gpu then multiple\n",
    "parallel_model = multi_gpu_model(model,3)\n",
    "with tf.device('/cpu:0'):\n",
    "    parallel_model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=1e-5),metrics=['accuracy'])                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CallBacks\n",
    "check_point = ModelCheckpoint(model_save_dir, monitor = \"val_loss\", verbose = 1,\n",
    "                              save_best_only = True, mode = \"min\")\n",
    "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n",
    "tbCallBack = TensorBoard(log_dir=tensorboard_dir,\n",
    "                         histogram_freq=1,\n",
    "                         write_graph=True,\n",
    "                         write_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Single gpu/cpu train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#first run model on single gpu then multiple\n",
    "with tf.device('/device:GPU:1'):\n",
    "    model.fit([trn_cat[:6000],trn_text[:6000]], encoded_target[:6000], batch_size=128, epochs=10, validation_split=0.2,callbacks=[check_point,early_stop,tbCallBack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-gpu train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first run model on single gpu then multiple\n",
    "parallel_model.fit([trn_cat[:60000],trn_text[:60000]], encoded_target[:60000], batch_size=128, epochs=5, validation_split=0.2,callbacks=[check_point,early_stop,tbCallBack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict([trn_cat[train_size:size],trn_text[train_size:size]],batch_size=batch_size)\n",
    "preds_classes = preds.argmax(axis=-1)\n",
    "predictions = lbl.inverse_transform(preds_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
